#################
# MedScore Configuration File
#################

# --- Main Input/Output Files ---
# These paths are relative to where you run the script.
input_file: "data/medexpert-benchmark.jsonl"
output_dir: "./"
response_key: "response"

# --- Decomposition Configuration ---
decomposer:
  type: "medscore"  # Options: medscore, factscore, dndscore, custom
  model_name: "gpt-4o-mini"
  server_path: "https://api.openai.com/v1"

# --- Verification Configuration ---
verifier:
  type: "medrag"
  # corpus_name: "Wikipedia"  # "PubMed", "Textbooks", "StatPearls", "Wikipedia", "MedCorp", "MEDIC"
  corpus_name: "MEDIC"
  n_returned_docs: 10
  cache: true  # Set to true for large datasets to improve performance
  db_dir: "."
  model_name: "mistralai/Mistral-Small-24B-Instruct-2501"
  server_path: "http://localhost:8000/v1"  # Set the vLLM server path based on your GPU server
